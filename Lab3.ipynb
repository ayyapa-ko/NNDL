{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Only if dataset is in Drive)\n",
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "\n",
    "# === Step 1: Mount Drive & Extract ZIP File ===\n",
    "\n",
    "\n",
    "# Paths (Update If Needed)\n",
    "zip_file = \"/content/train.zip\"  # Change this to the correct ZIP file path\n",
    "extract_folder = \"/content/trainimages\"  # Folder where images will be extracted\n",
    "csv_file = \"/content/trainLabels.csv\"  # Change if needed\n",
    "\n",
    "# Extract ZIP File\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as archive:\n",
    "    archive.extractall(extract_folder)\n",
    "\n",
    "# === Step 2: Load the Dataset ===\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define the image folder\n",
    "image_folder = \"/content/trainimages/train\" # This is the folder where images are extracted\n",
    "\n",
    "# === Step 3: Define a Function to Load & Preprocess Images ===\n",
    "def load_image(image_id, img_size=(32, 32)):\n",
    "    img_path = os.path.join(image_folder, f\"{image_id}.png\")  # Assuming PNG format\n",
    "    if os.path.exists(img_path):\n",
    "        img = imread(img_path)\n",
    "        img_resized = resize(img, img_size)  # Resize to 32x32\n",
    "        img_gray = rgb2gray(img_resized)  # Convert to grayscale\n",
    "        return img_gray\n",
    "    else:\n",
    "        print(f\"Image {image_id}.png not found!\")\n",
    "        return None\n",
    "\n",
    "# === Step 4: Convolution on 1D Signal (A1) ===\n",
    "X = [0,1,2,3,4,5,6,0,1,2,3,4,5,6,0,0,0]\n",
    "H_L = [0.05, 0.2, 0.5, 0.2, 0.05]  # Low-pass filter\n",
    "H_H = [-1, 2, -1]  # High-pass filter\n",
    "\n",
    "y_low = np.convolve(X, H_L, mode='same')\n",
    "y_high = np.convolve(X, H_H, mode='same')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(X, label=\"Original Signal\", linestyle=\"dashed\")\n",
    "plt.plot(y_low, label=\"Low-pass Filtered\")\n",
    "plt.plot(y_high, label=\"High-pass Filtered\")\n",
    "plt.legend()\n",
    "plt.title(\"1D Convolution with Filters\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 5: Convolution on Images (A2) ===\n",
    "sample_id = df[\"id\"][0]  # Load the first image\n",
    "img = load_image(sample_id)\n",
    "\n",
    "# Define filters\n",
    "fil1 = np.array([[ 0, -1,  0], [-1, 4, -1], [ 0, -1,  0]])  # Edge detection\n",
    "fil2 = np.array([[ 0.2, 0.5,  0.2], [0.5, 1, 0.5], [0.2, 0.5, 0.2]])  # Sharpen\n",
    "fil3 = np.ones((5,5)) / 25  # Smoothing\n",
    "\n",
    "# Apply filters\n",
    "grad1 = signal.convolve2d(img, fil1, boundary='symm', mode='same')\n",
    "grad2 = signal.convolve2d(img, fil2, boundary='symm', mode='same')\n",
    "grad3 = signal.convolve2d(img, fil3, boundary='symm', mode='same')\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15,5))\n",
    "axes[0].imshow(img, cmap=\"gray\"); axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(abs(grad1), cmap=\"gray\"); axes[1].set_title(\"Edge Detection\")\n",
    "axes[2].imshow(grad2, cmap=\"gray\"); axes[2].set_title(\"Sharpened\")\n",
    "axes[3].imshow(grad3, cmap=\"gray\"); axes[3].set_title(\"Smoothed\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 6: Load & Preprocess Images for Neural Network (A3-A5) ===\n",
    "image_size = (32, 32)\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img = load_image(row[\"id\"])\n",
    "    if img is not None:\n",
    "        X_data.append(img)\n",
    "        y_data.append(row[\"label\"])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_data = np.array(X_data).reshape(len(X_data), 32, 32, 1)  # Add channel dimension\n",
    "y_data = np.array(pd.factorize(y_data)[0])  # Convert labels to numeric\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-Hot Encoding Labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# === Step 7: Design & Train a Neural Network (A3) ===\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 1)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# === Step 8: Plot Training & Validation Loss (A4) ===\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 9: Evaluate the Model & Show Confusion Matrix (A5) ===\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
