{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Step 1: Import Libraries ===\n",
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import zipfile\n",
    "\n",
    "# === Step 2: Mount Google Drive (if needed) ===\n",
    "\n",
    "\n",
    "# Paths (Update If Needed)\n",
    "zip_file = \"/content/train.zip\"  # Change this to the correct ZIP file path\n",
    "extract_folder = \"/content/trainimages\"  # Folder where images will be extracted\n",
    "csv_file = \"/content/trainLabels.csv\"  # Change if needed\n",
    "\n",
    "# Extract ZIP File\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as archive:\n",
    "    archive.extractall(extract_folder)\n",
    "\n",
    "# Define the image folder\n",
    "image_folder = \"/content/trainimages/train\" # Update based on extracted structure\n",
    "\n",
    "# === Step 3: Load Dataset ===\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to load images\n",
    "def load_image(image_id, img_size=(28, 28)):\n",
    "    img_path = os.path.join(image_folder, f\"{image_id}.png\")  # Assuming PNG format\n",
    "    if os.path.exists(img_path):\n",
    "        img = imread(img_path)\n",
    "        img_resized = resize(img, img_size)  # Resize to 28x28\n",
    "        img_gray = rgb2gray(img_resized)  # Convert to grayscale\n",
    "        return img_gray\n",
    "    else:\n",
    "        print(f\"Image {image_id}.png not found!\")\n",
    "        return None\n",
    "\n",
    "# === Step 4: Preprocess Data ===\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img = load_image(row[\"id\"])\n",
    "    if img is not None:\n",
    "        X_data.append(img)\n",
    "        y_data.append(row[\"label\"])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_data = np.array(X_data).reshape(len(X_data), 28, 28, 1)  # Add channel dimension\n",
    "y_data = np.array(pd.factorize(y_data)[0])  # Convert labels to numbers\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-Hot Encoding Labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# === Step 5: Design CNN Model (A1) ===\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# === Step 6: Train CNN Model (A2) ===\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# === Step 7: Plot Training & Validation Loss (A3) ===\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 8: Evaluate Model Accuracy (A4) ===\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nCNN Model Accuracy:', score[1])\n",
    "\n",
    "# === Step 9: Inspect CNN Filters (A5) ===\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "# Plot first 5 filters\n",
    "for i in range(5):\n",
    "    plt.imshow(filters[:,:,0,i], cmap='gray')\n",
    "    plt.title(f\"Filter {i+1}\")\n",
    "    plt.show()\n",
    "\n",
    "# === Step 10: Inspect Filter Impact on an Image (A6) ===\n",
    "sample_image = X_train[10].reshape(28, 28)\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "# Apply filter to image\n",
    "filtered_image = signal.convolve2d(sample_image, filters[:,:,0,1].reshape(3,3), boundary='symm', mode='same')\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.title(\"Filtered Image\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 11: Design & Train Fully Connected Model (A7) ===\n",
    "fc_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "fc_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fc_history = fc_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# === Step 12: Plot Training vs Validation Loss (A8) ===\n",
    "plt.plot(fc_history.history['loss'], label='Training Loss')\n",
    "plt.plot(fc_history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Fully Connected Network - Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# === Step 13: Test & Evaluate Fully Connected Model (A8) ===\n",
    "fc_score = fc_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nFully Connected Network Accuracy:', fc_score[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
