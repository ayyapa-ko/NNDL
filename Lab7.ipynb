{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import zipfile\n",
    "\n",
    "# Unzipping the dataset\n",
    "zip_file = \"/content/train.zip\"\n",
    "extract_folder = \"/content/trainimages\"\n",
    "csv_file = \"/content/trainLabels.csv\"\n",
    "\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as archive:\n",
    "    archive.extractall(extract_folder)\n",
    "\n",
    "image_folder = \"/content/trainimages/train\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_id, img_size=(28, 28)):\n",
    "    img_path = os.path.join(image_folder, f\"{image_id}.png\")\n",
    "    if os.path.exists(img_path):\n",
    "        img = imread(img_path)\n",
    "        img_resized = resize(img, img_size)\n",
    "        img_gray = rgb2gray(img_resized)\n",
    "        return img_gray\n",
    "    else:\n",
    "        print(f\"Image {image_id}.png not found!\")\n",
    "        return None\n",
    "\n",
    "X_data, y_data = [], []\n",
    "for index, row in df.iterrows():\n",
    "    img = load_image(row[\"id\"])\n",
    "    if img is not None:\n",
    "        X_data.append(img)\n",
    "        y_data.append(row[\"label\"])\n",
    "\n",
    "X_data = np.array(X_data).reshape(len(X_data), 28, 28, 1)  # Add channel dimension\n",
    "y_data = np.array(pd.factorize(y_data)[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model with Regularization\n",
    "def create_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3,3), input_shape=(28, 28, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_cnn()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Print all layer names to find the correct one\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "# Use the correct layer name before the final Dense layer\n",
    "feature_extractor = Model(inputs=model.inputs, outputs=model.get_layer(\"dense_4\").output)  # Change \"dense_4\" if needed\n",
    "\n",
    "# Extract features\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n",
    "\n",
    "print(\"Feature extraction completed! Feature shape:\", X_train_features.shape)\n",
    "\n",
    "# Classifier using extracted features\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_features, y_train)\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Using SVM for classification\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_features, y_train)\n",
    "y_pred_svm = svm.predict(X_test_features)\n",
    "print(\"SVM Classifier Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Plot Training & Validation Loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss with Regularization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# ✅ Evaluate the model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\n✅ Regularized CNN Model Loss:', score[0])\n",
    "print('✅ Regularized CNN Model Accuracy:', score[1])\n",
    "\n",
    "# ✅ Predict class probabilities\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# ✅ Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# ✅ Ensure `y_test` is properly formatted\n",
    "if len(y_test.shape) == 1:  # If already categorical\n",
    "    y_true = y_test\n",
    "else:  # If one-hot encoded, convert back to class labels\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# ✅ Generate classification report\n",
    "num_classes = len(np.unique(y_true))  # Get actual number of classes\n",
    "report = classification_report(y_true, y_pred, target_names=[str(i) for i in range(num_classes)])\n",
    "\n",
    "# ✅ Print results\n",
    "print(\"\\n✅ Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
